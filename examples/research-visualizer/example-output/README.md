# Example Output

This folder contains an example research report generated using the `research-visualizer` composite skill.

## Source Topic

- **Topic**: How Transformers Work in AI
- **Research Method**: Web search for authoritative sources

## Generated Files

| File | Description |
|------|-------------|
| `transformer-research.md` | AI-generated research report with diagrams |

## How It Was Generated

The skill followed this workflow:

1. **Deep Research Phase**
   - Searched for "transformer architecture attention mechanism"
   - Gathered information from Wikipedia, DataCamp, IBM, arXiv
   - Identified key concepts: QKV attention, multi-head, parallelization

2. **Visualization Phase** - Created 5 mermaid diagrams:
   - Flowchart: Transformer architecture pipeline
   - Flowchart: QKV attention calculation
   - Flowchart: RNN vs Transformer comparison
   - Mindmap: Multi-head attention purposes
   - Timeline: Transformer evolution 2017-2024
   - Mindmap: Key takeaways summary

3. **Compiled Report** with:
   - Executive summary
   - Sections with inline diagrams
   - Comparison table (RNN vs Transformer)
   - Sources cited

## Diagrams Generated

| Concept | Diagram Type |
|---------|--------------|
| Architecture Overview | Flowchart TD |
| QKV Attention | Flowchart LR |
| RNN vs Transformer | Flowchart TB |
| Multi-Head Purposes | Mindmap |
| Evolution Timeline | Timeline |
| Key Takeaways | Mindmap |
